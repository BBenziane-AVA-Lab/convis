
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>convis.base &#8212; convis 0.5.1.1 documentation</title>
    <link rel="stylesheet" href="../../_static/haiku.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '0.5.1.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
  </head>
  <body>
      <div class="header" role="banner"><h1 class="heading"><a href="../../index.html">
          <span>convis 0.5.1.1 documentation</span></a></h1>
        <h2 class="heading"><span>convis.base</span></h2>
      </div>
      <div class="topnav" role="navigation" aria-label="top navigation">
      
        <p>
        <a class="uplink" href="../../index.html">Contents</a>
        </p>

      </div>
      <div class="content">
        
        
  <h1>Source code for convis.base</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Convis base classes</span>
<span class="sd">----------------------</span>

<span class="sd">Convis extends PyTorch by adding some methods to `torch.nn.Module` and calling it a Layer.</span>



<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">print_function</span>
<span class="kn">from</span> <span class="nn">.misc_utils</span> <span class="k">import</span> <span class="n">unique_list</span><span class="p">,</span> <span class="n">suppress</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pylab</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">uuid</span>
<span class="kn">from</span> <span class="nn">.</span> <span class="k">import</span> <span class="n">io</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">exceptions</span> <span class="k">import</span> <span class="ne">NotImplementedError</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="k">pass</span>
<span class="kn">from</span> <span class="nn">.variable_describe</span> <span class="k">import</span> <span class="n">describe</span><span class="p">,</span> <span class="n">describe_dict</span><span class="p">,</span> <span class="n">describe_html</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="kn">from</span> <span class="nn">.</span> <span class="k">import</span> <span class="n">variables</span>
<span class="kn">from</span> <span class="nn">.</span> <span class="k">import</span> <span class="n">variable_describe</span>
<span class="kn">from</span> <span class="nn">.variables</span> <span class="k">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">.</span> <span class="k">import</span> <span class="n">utils</span>
<span class="kn">from</span> <span class="nn">.</span> <span class="k">import</span> <span class="n">o</span>
<span class="kn">from</span> <span class="nn">.</span> <span class="k">import</span> <span class="n">optimizer</span>
<span class="kn">from</span> <span class="nn">.o</span> <span class="k">import</span> <span class="n">O</span><span class="p">,</span> <span class="n">Ox</span><span class="p">,</span> <span class="n">save_name</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="k">import</span> <span class="n">OrderedDict</span>

<span class="c1"># ----</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="k">import</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">datetime</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">functools</span> <span class="k">import</span> <span class="n">reduce</span>
<span class="k">except</span><span class="p">:</span>
    <span class="k">pass</span>

<span class="kn">from</span> <span class="nn">.variables</span> <span class="k">import</span> <span class="n">Variable</span><span class="p">,</span> <span class="n">State</span><span class="p">,</span> <span class="n">Parameter</span><span class="p">,</span> <span class="n">as_parameter</span><span class="p">,</span> <span class="n">is_variable</span>
<span class="kn">from</span> <span class="nn">copy</span> <span class="k">import</span> <span class="n">deepcopy</span>

<span class="n">TIME_DIMENSION</span> <span class="o">=</span> <span class="mi">2</span>

<span class="c1">### Node and Model classes</span>

<span class="k">def</span> <span class="nf">len_parents</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="s1">&#39;parent&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">n</span><span class="o">.</span><span class="n">parent</span> <span class="o">!=</span> <span class="n">n</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">len_parents</span><span class="p">(</span><span class="n">n</span><span class="o">.</span><span class="n">parent</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span>
    <span class="k">return</span> <span class="mi">0</span>

<div class="viewcode-block" id="Output"><a class="viewcode-back" href="../../docs.html#convis.base.Output">[docs]</a><span class="k">class</span> <span class="nc">Output</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This object provides a container for output numpy arrays which are labeled with theano variables.</span>

<span class="sd">        The outputs can be queried either by sorted order (like a simple list),</span>
<span class="sd">        by the theano variable which represents this output, the name of this variable</span>
<span class="sd">        or the full path of the variable.</span>
<span class="sd">        To make this meaningfull, provide a name to your output variables.</span>

<span class="sd">        In the case of name collisions, the behavior of OrderedDict will use the last variable added.</span>

<span class="sd">        The full path names of all variables are also added to this objects __dict__,</span>
<span class="sd">        allowing for tab completion.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">outs</span><span class="p">,</span><span class="n">keys</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            The full path names of all variables are also added to this objects __dict__,</span>
<span class="sd">            allowing for tab completion.</span>

<span class="sd">            By default returns a numpy array when used with square brackets, the </span>
<span class="sd">            Variable when accessed over `._outs[n]`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_out_dict</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">({})</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_out_dict_by_full_names</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">({})</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_out_dict_by_short_names</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">({})</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_outs</span> <span class="o">=</span> <span class="n">outs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">keys</span> <span class="o">=</span> <span class="n">keys</span>
        <span class="k">if</span> <span class="n">keys</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_out_dict</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">keys</span><span class="p">,</span><span class="n">outs</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_out_dict_by_full_names</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">([(</span><span class="n">full_path</span><span class="p">(</span><span class="n">k</span><span class="p">),</span><span class="n">o</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="n">o</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">keys</span><span class="p">,</span><span class="n">outs</span><span class="p">)])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_out_dict_by_short_names</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">([(</span><span class="n">save_name</span><span class="p">(</span><span class="n">get_convis_attribute</span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="s1">&#39;name&#39;</span><span class="p">)),</span><span class="n">o</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="n">o</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">keys</span><span class="p">,</span><span class="n">outs</span><span class="p">)</span> <span class="k">if</span> <span class="n">has_convis_attribute</span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="s1">&#39;name&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">type</span><span class="p">(</span><span class="n">get_convis_attribute</span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="s1">&#39;name&#39;</span><span class="p">))</span> <span class="ow">is</span> <span class="nb">str</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_out_dict</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_outs</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_outs</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">plot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">k</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">utils</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="bp">self</span><span class="p">[</span><span class="n">k</span><span class="p">],</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">array</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">k</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">[</span><span class="n">k</span><span class="p">])</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">variable</span><span class="o">.</span><span class="n">Variable</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">k</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">int</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_outs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_out_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_out_dict</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">save_name</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_out_dict_by_short_names</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_out_dict_by_short_names</span><span class="p">[</span><span class="n">save_name</span><span class="p">(</span><span class="n">k</span><span class="p">)]</span>
            <span class="k">if</span> <span class="n">save_name</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_out_dict_by_full_names</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_out_dict_by_full_names</span><span class="p">[</span><span class="n">save_name</span><span class="p">(</span><span class="n">k</span><span class="p">)]</span>
        <span class="k">if</span> <span class="nb">str</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="o">!=</span> <span class="n">save_name</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">IndexError</span><span class="p">(</span><span class="s1">&#39;Key not found: &#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">k</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39; / &#39;</span><span class="o">+</span><span class="n">save_name</span><span class="p">(</span><span class="n">k</span><span class="p">))</span>
        <span class="k">raise</span> <span class="ne">IndexError</span><span class="p">(</span><span class="s1">&#39;Key not found: &#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">k</span><span class="p">))</span></div>

<span class="k">class</span> <span class="nc">_OptimizerSelection</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A single optimizer option that can be called to set this optimizer for the model.</span>
<span class="sd">        The doc string of the original optimizer is available by calling `help()` on this object.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">opt</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_opt</span> <span class="o">=</span> <span class="n">opt</span>
        <span class="bp">self</span><span class="o">.</span><span class="vm">__doc__</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_opt</span><span class="o">.</span><span class="vm">__doc__</span>
    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="o">*</span><span class="n">args</span><span class="p">,</span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">set_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_opt</span><span class="p">,</span><span class="o">*</span><span class="n">args</span><span class="p">,</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">_OptimizerSelector</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Enables tab completion to set optimizers for a model.</span>
<span class="sd">        Includes all Optimizers found in `torch.nn.optim` and</span>
<span class="sd">        `convis.optimizer`.</span>

<span class="sd">        If optimizers are added to torch during runtime,</span>
<span class="sd">        you can call `._reload()` to add all available options.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="p">,</span> <span class="n">o</span><span class="p">))</span> <span class="ow">is</span> <span class="nb">type</span> <span class="ow">and</span> <span class="nb">issubclass</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="p">,</span> <span class="n">o</span><span class="p">),</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">):</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">o</span><span class="p">,</span> <span class="n">_OptimizerSelection</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="p">,</span><span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="p">,</span> <span class="n">o</span><span class="p">)))</span>
        <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="n">optimizer</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">o</span><span class="p">))</span> <span class="ow">is</span> <span class="nb">type</span> <span class="ow">and</span> <span class="nb">issubclass</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">o</span><span class="p">),</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">):</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">o</span><span class="p">,</span> <span class="n">_OptimizerSelection</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="p">,</span><span class="nb">getattr</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">o</span><span class="p">)))</span>
    <span class="k">def</span> <span class="nf">_reload</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="p">,</span> <span class="n">o</span><span class="p">))</span> <span class="ow">is</span> <span class="nb">type</span> <span class="ow">and</span> <span class="nb">issubclass</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="p">,</span> <span class="n">o</span><span class="p">),</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">):</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">o</span><span class="p">,</span> <span class="n">_OptimizerSelection</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="p">,</span><span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="p">,</span> <span class="n">o</span><span class="p">)))</span>
        <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="n">optimizer</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">o</span><span class="p">))</span> <span class="ow">is</span> <span class="nb">type</span> <span class="ow">and</span> <span class="nb">issubclass</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">o</span><span class="p">),</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">):</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">o</span><span class="p">,</span> <span class="n">_OptimizerSelection</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="p">,</span><span class="nb">getattr</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">o</span><span class="p">)))</span>
    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">opt</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="kn">import</span> <span class="nn">types</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="ow">is</span> <span class="ow">not</span> <span class="nb">list</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">types</span><span class="o">.</span><span class="n">GeneratorType</span><span class="p">)):</span>
            <span class="n">args</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
            <span class="n">args</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
        <span class="k">if</span> <span class="nb">issubclass</span><span class="p">(</span><span class="n">opt</span><span class="p">,</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="o">.</span><span class="n">_optimizer</span> <span class="o">=</span> <span class="n">opt</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">opt</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">str</span> <span class="ow">and</span> <span class="nb">issubclass</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="p">,</span> <span class="n">opt</span><span class="p">),</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">):</span>
            <span class="bp">self</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="p">,</span> <span class="n">opt</span><span class="p">),</span><span class="o">*</span><span class="n">args</span><span class="p">,</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="prepare_input"><a class="viewcode-back" href="../../docs.html#convis.base.prepare_input">[docs]</a><span class="k">def</span> <span class="nf">prepare_input</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">cuda</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">volatile</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Utility function to broadcast input to 5 dimensions, make it a Tensor,</span>
<span class="sd">        wrap it in a Variable and optionally move it to the GPU.</span>

<span class="sd">        Short hand for::</span>

<span class="sd">            import torch</span>
<span class="sd">            a_var = torch.autograd.Variable(torch.Tensor(a[None,None,:,:,:]), requires_grad=True).cuda()</span>

<span class="sd">            from convis.base import prepare_input</span>
<span class="sd">            a_var = prepare_input(a, cuda=True, requires_grad=True)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">type</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="ow">is</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">Variable</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="s1">&#39;numpy&#39;</span><span class="p">):</span>
            <span class="c1"># its hopefully a torch.Tensor</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">volatile</span><span class="o">=</span><span class="n">volatile</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="n">requires_grad</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">a</span><span class="p">),</span> <span class="n">volatile</span><span class="o">=</span><span class="n">volatile</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="n">requires_grad</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">dims</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">dims</span> <span class="o">==</span> <span class="mi">5</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
                <span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span><span class="kc">None</span><span class="p">,:,:,:]</span>
        <span class="k">if</span> <span class="n">dims</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">5</span><span class="p">:</span>
                <span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,:,:,:]</span>
    <span class="k">if</span> <span class="n">cuda</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">cuda</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">a</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">a</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span></div>

<div class="viewcode-block" id="shape"><a class="viewcode-back" href="../../docs.html#convis.base.shape">[docs]</a><span class="k">def</span> <span class="nf">shape</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return the shape of a Tensor or Variable containing a Tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="s1">&#39;shape&#39;</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="s1">&#39;data&#39;</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">data</span><span class="p">,</span><span class="s1">&#39;shape&#39;</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;No shape found for &#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39;!&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="Layer"><a class="viewcode-back" href="../../docs.html#convis.base.Layer">[docs]</a><span class="k">class</span> <span class="nc">Layer</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Base class for modules, layers and models.</span>

<span class="sd">        `convis.Layer` is a `torch.nn.Module` with some added functionality::</span>

<span class="sd">            import convis</span>
<span class="sd">            import torch.nn.functional as F</span>

<span class="sd">            class Model(convis.Layer):</span>
<span class="sd">                def __init__(self):</span>
<span class="sd">                    super(Model, self).__init__()</span>
<span class="sd">                    self.conv1 = convis.filters.Conv3d(1, (20,1,1))</span>
<span class="sd">                    self.conv2 = convis.filters.Conv3d(1, (1,10,10))</span>
<span class="sd">                def forward(self, x):</span>
<span class="sd">                   x = F.relu(self.conv1(x))</span>
<span class="sd">                   return F.relu(self.conv2(x))</span>

<span class="sd">        Just as `Module`s, `Layer`s can include other `Layer`s or `Module`s (ie. its `sublayers`).</span>
<span class="sd">        `Variable`s, `Parameter`s and `State`s that are attributes of a Layer or</span>
<span class="sd">        its `sublayers` will be registered and can be collected according to their</span>
<span class="sd">        class.</span>
<span class="sd">        </span>
<span class="sd">        All registered Variables (including Parameters and States), will be moved to the</span>
<span class="sd">        corresponding device when calling `.cuda()` or `.cpu()`.</span>

<span class="sd">        In contrast to many methods of torch.Tensors, Layer methods are always</span>
<span class="sd">        in-place! Using `.cuda()` or `.float()` will return a reference to the </span>
<span class="sd">        original model and not a copy.</span>


<span class="sd">        Attributes</span>
<span class="sd">        ----------</span>

<span class="sd">        _use_cuda : bool</span>

<span class="sd">        .. py:attribute:: set_optimizer</span>

<span class="sd">            :class:`magic object &lt;convis.base._OptimizerSelector&gt;` that allows </span>
<span class="sd">            tab completion to select an optimizer. (see :ref:`example &lt;tab_completion_example&gt;`)</span>


<span class="sd">            The list of parameters as first argument can be omitted</span>
<span class="sd">            and will be filled with all parameters of the model by</span>
<span class="sd">            default. Other parameters are passed through to the optimizer.</span>

<span class="sd">        .. py:attribute:: user_parameteres</span>

<span class="sd">            A hierarchical, tab-completable list of all :class:`~torch.nn.Parameter`s/:class:`~convis.variables.Parameter`s</span>
<span class="sd">            /:class:`~convis.variables.VirtualParameter`s of the model that provide a `.set()` function for the user.</span>

<span class="sd">        .. py:attribute:: m</span>

<span class="sd">            A hierarchical, tab-completable list of all :class:`~torch.nn.Module`s/:class:`~convis.base.Layer`s of the model.</span>

<span class="sd">        .. py:attribute:: s</span>

<span class="sd">            A hierarchical, tab-completable list of all state variables of the model.</span>


<span class="sd">        Methods</span>
<span class="sd">        -------</span>

<span class="sd">        cuda(device=None)</span>
<span class="sd">            move the model to the gpu</span>
<span class="sd">        cpu()</span>
<span class="sd">            move the model to the cpu</span>

<span class="sd">        run(the_input, dt=None)</span>
<span class="sd">            execute the model, using chunk sizes of `dt`</span>

<span class="sd">        parse_config(conf)</span>

<span class="sd">        optimize(inp,outp,dt=None)</span>
<span class="sd">            use the selected optimizer to fit the model</span>
<span class="sd">            to return outp to the input inp.</span>
<span class="sd">            Accepts a chunk length `dt`</span>

<span class="sd">        register_state(name, value)</span>
<span class="sd">            registers an attribute name to be a state variable</span>
<span class="sd">        </span>
<span class="sd">        state()</span>
<span class="sd">            returns the current state of the model</span>
<span class="sd">            (recursively for all submodules)</span>

<span class="sd">        set_state(d)</span>
<span class="sd">            set all state parameters defined in dictionary `d`</span>
<span class="sd">            to the corresponding values.</span>

<span class="sd">        push_state()</span>
<span class="sd">            pushes the current state on a stack</span>

<span class="sd">        pop_state()</span>
<span class="sd">            pops the last state from the stack</span>
<span class="sd">            and sets all state variables to the </span>
<span class="sd">            corresponding values.</span>



<span class="sd">        Examples</span>
<span class="sd">        --------</span>


<span class="sd">        &gt;&gt;&gt; import convis</span>
<span class="sd">        &gt;&gt;&gt; import torch.nn.functional as F</span>
<span class="sd">        &gt;&gt;&gt; </span>
<span class="sd">        &gt;&gt;&gt; class Model(convis.Layer):</span>
<span class="sd">        &gt;&gt;&gt;     def __init__(self):</span>
<span class="sd">        &gt;&gt;&gt;         super(Model, self).__init__()</span>
<span class="sd">        &gt;&gt;&gt;         self.conv1 = convis.filters.Conv3d(1, (20,1,1))</span>
<span class="sd">        &gt;&gt;&gt;         self.conv2 = convis.filters.Conv3d(1, (1,10,10))</span>
<span class="sd">        &gt;&gt;&gt;     def forward(self, x):</span>
<span class="sd">        &gt;&gt;&gt;        x = F.relu(self.conv1(x))</span>
<span class="sd">        &gt;&gt;&gt;        return F.relu(self.conv2(x))</span>


<span class="sd">        .. _tab_completion_example:</span>

<span class="sd">        Selecting an :class:`~torch.optim.Optimizer` and using it with :meth:`~convis.base.Layer.optimize`:</span>

<span class="sd">        &gt;&gt;&gt; m = convis.models.LN()</span>
<span class="sd">        &gt;&gt;&gt; m.set_optimizer.&lt;then press tab&gt;</span>
<span class="sd">                            ASGD</span>
<span class="sd">                            Adadelta</span>
<span class="sd">                            Adagrad</span>
<span class="sd">                            Adam</span>
<span class="sd">                            ...</span>
<span class="sd">        &gt;&gt;&gt; m.set_optimizer.SGD(lr=0.01)</span>
<span class="sd">        &gt;&gt;&gt; m.optimize(input,output)</span>

<span class="sd">        The list of parameters as first argument can be omitted</span>
<span class="sd">        and will be filled with all parameters of the model by</span>
<span class="sd">        default. Other parameters are passed through to the optimizer</span>
<span class="sd">        eg. the learning rate :attr:`lr` in this example.</span>


<span class="sd">        .. _tab_completion_special_attributes_example:</span>

<span class="sd">        The special attributes `p`,`m`,`s` and `user_parameters`</span>
<span class="sd">        provide tab-completion for parameters, submodules and states:</span>

<span class="sd">        &gt;&gt;&gt; retina = convis.models.retina()</span>
<span class="sd">        &gt;&gt;&gt; print retina.p</span>
<span class="sd">        Parameters of the model (see also .user_parameters)</span>
<span class="sd">        Choices: gang_0_spikes, gang_1_spikes, gang_0_input, gang_1_input, bipolar, opl</span>
<span class="sd">        &gt;&gt;&gt; print retina.user_parameters</span>
<span class="sd">        Parameters of the model that can be set by the user.</span>
<span class="sd">        Choices: gang_0_spikes, gang_1_spikes, gang_0_input, gang_1_input, bipolar, opl</span>
<span class="sd">        &gt;&gt;&gt; print retina.p</span>
<span class="sd">        Modules of the model</span>
<span class="sd">        Choices: _self, gang_0_spikes, gang_1_spikes, gang_0_input, gang_1_input, bipolar, opl</span>
<span class="sd">        &gt;&gt;&gt; print retina.s</span>
<span class="sd">        Current state of the model</span>
<span class="sd">        Choices: gang_0_spikes, gang_1_spikes, gang_0_input, gang_1_input, bipolar, opl</span>

<span class="sd">        To find explore the parameters / modules / states,</span>
<span class="sd">        print the object to see the available choices or</span>
<span class="sd">        press tab:</span>

<span class="sd">        &gt;&gt;&gt; retina.p.&lt;tab complete&gt;</span>
<span class="sd">        &gt;&gt;&gt; retina.p.bi&lt;tab complete&gt;</span>
<span class="sd">        &gt;&gt;&gt; retina.p.bipolar.&lt;tab complete&gt;</span>
<span class="sd">        &gt;&gt;&gt; retina.p.bipolar.g_leak # the g_leak Parameter</span>

<span class="sd">        The hierarchical :class:`~convis.o.Ox` object provides </span>
<span class="sd">        a few special functions</span>

<span class="sd">        &gt;&gt;&gt; retina.p._all.bipolar_g_leak # lists everything in a flat list</span>
<span class="sd">        &gt;&gt;&gt; retina.p._search.leak.&lt;tab complete to search&gt;</span>
<span class="sd">        &gt;&gt;&gt; retina.p._search.leak.bipolar_g_leak # found one result</span>



<span class="sd">        See Also</span>
<span class="sd">        --------</span>

<span class="sd">        torch.nn.Module : torchs layer class</span>


<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_state</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_state</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_default_state</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Layer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_variables</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_named_variables</span><span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_use_cuda</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_optimizer</span> <span class="o">=</span> <span class="n">_OptimizerSelector</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">register_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">name</span><span class="p">,</span><span class="n">val</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">name</span><span class="p">)</span> <span class="ow">and</span> <span class="n">val</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_state</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">name</span><span class="p">,</span><span class="kc">None</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_state</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">val</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_default_state</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
<div class="viewcode-block" id="Layer.cuda"><a class="viewcode-back" href="../../docs.html#convis.base.Layer.cuda">[docs]</a>    <span class="k">def</span> <span class="nf">cuda</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Moves the model to the GPU (optionally with number `device`).</span>
<span class="sd">            returns the model itself.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_use_cuda</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">m</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">self</span><span class="p">:</span>
                <span class="n">m</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">Layer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">Layer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span></div>
<div class="viewcode-block" id="Layer.cpu"><a class="viewcode-back" href="../../docs.html#convis.base.Layer.cpu">[docs]</a>    <span class="k">def</span> <span class="nf">cpu</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Moves the model to the CPU and returns the model itself.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_use_cuda</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">m</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">self</span><span class="p">:</span>
                <span class="n">m</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">Layer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span></div>
    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="o">*</span><span class="n">args</span><span class="p">,</span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">new_args</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">args</span><span class="p">:</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">prepare_input</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;dims&#39;</span><span class="p">,</span><span class="kc">None</span><span class="p">),</span> <span class="n">cuda</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_use_cuda</span><span class="p">)</span>
            <span class="n">new_args</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="n">o0</span> <span class="o">=</span> <span class="n">o</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">Layer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__call__</span><span class="p">(</span><span class="o">*</span><span class="n">new_args</span><span class="p">,</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;outputs&#39;</span><span class="p">):</span>
            <span class="n">o</span> <span class="o">=</span> <span class="n">Output</span><span class="p">([</span><span class="n">o</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">],</span> <span class="n">keys</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;output&#39;</span><span class="p">]</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">o</span>
<div class="viewcode-block" id="Layer.run"><a class="viewcode-back" href="../../docs.html#convis.base.Layer.run">[docs]</a>    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">the_input</span><span class="p">,</span><span class="n">dt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">t</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Runs the model either once, or multiple times to process chunks of size `dt`.</span>

<span class="sd">            Returns an `Output` object.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">dt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run_in_chunks</span><span class="p">(</span><span class="n">the_input</span><span class="p">,</span><span class="n">dt</span><span class="o">=</span><span class="n">dt</span><span class="p">,</span><span class="n">t</span><span class="o">=</span><span class="n">t</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">Output</span><span class="p">(</span><span class="bp">self</span><span class="p">(</span><span class="n">the_input</span><span class="p">),</span><span class="n">keys</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;output&#39;</span><span class="p">])</span></div>
    <span class="k">def</span> <span class="nf">_run_in_chunks</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">the_input</span><span class="p">,</span><span class="n">dt</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span><span class="n">t</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="n">chunked_output</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;output&#39;</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">(</span><span class="n">the_input</span><span class="p">))</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">the_input</span> <span class="o">=</span> <span class="n">the_input</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span><span class="kc">None</span><span class="p">,:,:,:]</span>
        <span class="k">while</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="n">shape</span><span class="p">(</span><span class="n">the_input</span><span class="p">)[</span><span class="mi">2</span><span class="p">]:</span>
            <span class="n">oo</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">the_input</span><span class="p">[:,:,</span><span class="n">t</span><span class="p">:(</span><span class="n">t</span><span class="o">+</span><span class="n">dt</span><span class="p">),:,:])</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">oo</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">Output</span><span class="p">:</span>
                <span class="n">oo</span> <span class="o">=</span> <span class="p">[</span><span class="n">oo</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">keys</span><span class="o">=</span><span class="n">oo</span><span class="o">.</span><span class="n">keys</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">o</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">oo</span><span class="p">):</span>
                <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">chunked_output</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span>
                    <span class="n">chunked_output</span><span class="o">.</span><span class="n">append</span><span class="p">([])</span>
                <span class="n">chunked_output</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">o</span><span class="p">)</span>
            <span class="n">t</span> <span class="o">+=</span> <span class="n">dt</span>
        <span class="n">outs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">co</span> <span class="ow">in</span> <span class="n">chunked_output</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">outs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">co</span><span class="p">,</span><span class="n">dim</span><span class="o">=</span><span class="n">TIME_DIMENSION</span><span class="p">))</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">outs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">co</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">Output</span><span class="p">(</span><span class="n">outs</span><span class="p">,</span><span class="n">keys</span><span class="o">=</span><span class="n">keys</span><span class="p">)</span>
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">p</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            A hierarchical, tab-completable list of all :class:`torch.nn.parameter.Parameter` of the model.</span>
<span class="sd">            If a parameters is reachable via `some_model.p.layer1.module1.parameter1`</span>
<span class="sd">            it will also be available directly as `some_model.layer1.module1.parameter1`.</span>
<span class="sd">            However for tab-completion, the later method provides *all* attributes</span>
<span class="sd">            of the model, not only parameters.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">variables</span><span class="o">.</span><span class="n">create_Ox_from_torch_iterator_dicts</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">(),</span>
            <span class="n">doc</span><span class="o">=</span><span class="s1">&#39;Parameters of the model (tab-completable, includes also parameters that should not be changed by the user. See also .user_parameters)&#39;</span><span class="p">)</span>
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">user_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">variables</span><span class="o">.</span><span class="n">create_Ox_from_torch_iterator_dicts</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="s1">&#39;set&#39;</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()),</span>
            <span class="n">doc</span><span class="o">=</span><span class="s1">&#39;Parameters of the model that can be set by the user via `.set()`. (tab-completable)&#39;</span><span class="p">)</span>
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">m</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">variables</span><span class="o">.</span><span class="n">create_Ox_from_torch_iterator_dicts</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">named_modules</span><span class="p">(),</span>
            <span class="n">doc</span><span class="o">=</span><span class="s1">&#39;Modules of the model (tab-completable)&#39;</span><span class="p">)</span>
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">s</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">variables</span><span class="o">.</span><span class="n">create_Ox_from_torch_iterator_dicts</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">(),</span>
            <span class="n">doc</span><span class="o">=</span><span class="s1">&#39;Current state of the model (tab-completable)&#39;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">_apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fn</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">():</span>
            <span class="n">module</span><span class="o">.</span><span class="n">_apply</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_variables</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">var</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># Variables stored in modules are graph leaves, and we don&#39;t</span>
                <span class="c1"># want to create copy nodes, so we have to unpack the data.</span>
                <span class="n">var</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">fn</span><span class="p">(</span><span class="n">var</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">var</span><span class="o">.</span><span class="n">_grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">var</span><span class="o">.</span><span class="n">_grad</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">fn</span><span class="p">(</span><span class="n">var</span><span class="o">.</span><span class="n">_grad</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_parameters</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">param</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># Variables stored in modules are graph leaves, and we don&#39;t</span>
                <span class="c1"># want to create copy nodes, so we have to unpack the data.</span>
                <span class="n">param</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">fn</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">_grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">param</span><span class="o">.</span><span class="n">_grad</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">fn</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">_grad</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">buf</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_buffers</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">buf</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_buffers</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">fn</span><span class="p">(</span><span class="n">buf</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span>
    <span class="k">def</span> <span class="nf">__dir__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;_state&#39;</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_state</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="o">+</span> <span class="nb">super</span><span class="p">(</span><span class="n">Layer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__dir__</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="o">+</span> <span class="nb">super</span><span class="p">(</span><span class="n">Layer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__dir__</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">__setattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">):</span>
            <span class="nb">super</span><span class="p">(</span><span class="n">Layer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_state</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_state</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
        <span class="k">if</span> <span class="n">is_variable</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="o">==</span> <span class="n">Parameter</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_parameters</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_variables</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_named_variables</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
            <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">super</span><span class="p">(</span><span class="n">Layer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">__getattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">):</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">Layer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__getattr__</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_state</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_state</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">Layer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__getattr__</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
<div class="viewcode-block" id="Layer.parse_config"><a class="viewcode-back" href="../../docs.html#convis.base.Layer.parse_config">[docs]</a>    <span class="k">def</span> <span class="nf">parse_config</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">config</span><span class="p">,</span><span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span><span class="n">key</span><span class="o">=</span><span class="s1">&#39;retina_config_key&#39;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Loads parameter values from a configuration (RetinaConfiguration or dict).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="s1">&#39;_variables&#39;</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">a</span><span class="o">.</span><span class="n">_variables</span><span class="p">:</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="s1">&#39;retina_config_key&#39;</span><span class="p">):</span>
                        <span class="k">if</span> <span class="n">v</span><span class="o">.</span><span class="n">retina_config_key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="p">):</span>
                            <span class="k">continue</span>
                        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="s1">&#39;set&#39;</span><span class="p">):</span>
                            <span class="k">try</span><span class="p">:</span>
                                <span class="n">v</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">prefix</span><span class="o">+</span><span class="n">v</span><span class="o">.</span><span class="n">retina_config_key</span><span class="p">))</span>
                            <span class="k">except</span><span class="p">:</span>
                                <span class="k">pass</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;has no set:&#39;</span><span class="p">,</span><span class="n">v</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">f</span><span class="p">)</span></div>
<div class="viewcode-block" id="Layer.optimize"><a class="viewcode-back" href="../../docs.html#convis.base.Layer.optimize">[docs]</a>    <span class="k">def</span> <span class="nf">optimize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">outp</span><span class="p">,</span> <span class="n">optimizer</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">loss_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">:</span> <span class="p">((</span><span class="n">x</span><span class="o">-</span><span class="n">y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span> <span class="n">dt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Runs an Optimizer to fit the models parameters such that the output</span>
<span class="sd">            of the model when presented :attr:`inp` approximates :attr:`outp`.</span>

<span class="sd">            To use this function, an :class:`torch.optim.Optimizer` has to be selected::</span>

<span class="sd">                &gt;&gt;&gt; model.set_optimizer(torch.optim.SGD(model.parameters(),lr=0.01))</span>
<span class="sd">                &gt;&gt;&gt; model.optimize(x,y, dt=100)</span>

<span class="sd">            or::</span>

<span class="sd">                &gt;&gt;&gt; model.set_optimizer.SGD(lr=0.01) # uses optimizers from torch.optim</span>
<span class="sd">                &gt;&gt;&gt; model.optimize(x,y, dt=100)</span>

<span class="sd">            It is important to specify a chunk length :attr:`dt`, if the complete input does not fit into memory.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">optimizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;Optimizer has to be set! Use .set_optimizer.&lt;tab&gt;&#39;</span>
            <span class="n">optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span>
        <span class="k">def</span> <span class="nf">closure</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pop_state</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">push_state</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">o</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">closure</span><span class="o">.</span><span class="n">inp</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">closure</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">closure</span><span class="o">.</span><span class="n">outp</span><span class="p">,</span><span class="n">o</span><span class="p">)</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">loss</span>
        <span class="n">inp</span> <span class="o">=</span> <span class="n">prepare_input</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;dims&#39;</span><span class="p">,</span><span class="kc">None</span><span class="p">),</span> <span class="n">cuda</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_use_cuda</span><span class="p">)</span>
        <span class="n">outp</span> <span class="o">=</span> <span class="n">prepare_input</span><span class="p">(</span><span class="n">outp</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="s1">&#39;dims&#39;</span><span class="p">,</span><span class="kc">None</span><span class="p">),</span> <span class="n">cuda</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_use_cuda</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">push_state</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">dt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">steps</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">while</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="n">shape</span><span class="p">(</span><span class="n">inp</span><span class="p">)[</span><span class="n">TIME_DIMENSION</span><span class="p">]:</span>
                <span class="n">closure</span><span class="o">.</span><span class="n">inp</span> <span class="o">=</span> <span class="n">inp</span><span class="p">[:,:,</span><span class="n">t</span><span class="p">:(</span><span class="n">t</span><span class="o">+</span><span class="n">dt</span><span class="p">),:,:]</span>
                <span class="n">closure</span><span class="o">.</span><span class="n">outp</span> <span class="o">=</span> <span class="n">outp</span><span class="p">[:,:,</span><span class="n">t</span><span class="p">:(</span><span class="n">t</span><span class="o">+</span><span class="n">dt</span><span class="p">),:,:]</span>
                <span class="n">t</span> <span class="o">+=</span> <span class="n">dt</span>
                <span class="n">closure</span><span class="o">.</span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">loss_fn</span>
                <span class="n">steps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">closure</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">steps</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">closure</span><span class="o">.</span><span class="n">inp</span> <span class="o">=</span> <span class="n">inp</span>
            <span class="n">closure</span><span class="o">.</span><span class="n">outp</span> <span class="o">=</span> <span class="n">outp</span>
            <span class="n">closure</span><span class="o">.</span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">loss_fn</span>
            <span class="k">return</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">closure</span><span class="p">)</span></div>
<div class="viewcode-block" id="Layer.state"><a class="viewcode-back" href="../../docs.html#convis.base.Layer.state">[docs]</a>    <span class="k">def</span> <span class="nf">state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            collects the state and returns an</span>
<span class="sd">            OrderedDict </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">def</span> <span class="nf">rec</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
            <span class="n">o</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="s1">&#39;_state&#39;</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">s_name</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">_state</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="n">o</span><span class="p">[</span><span class="n">s_name</span><span class="p">]</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">s_name</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">mod_name</span><span class="p">,</span><span class="n">mod</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">named_modules</span><span class="p">()):</span>
                <span class="k">if</span> <span class="n">mod</span> <span class="ow">is</span> <span class="n">model</span><span class="p">:</span>
                    <span class="k">continue</span>
                <span class="k">for</span> <span class="n">s_name</span><span class="p">,</span><span class="n">s</span> <span class="ow">in</span> <span class="n">rec</span><span class="p">(</span><span class="n">mod</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="n">o</span><span class="p">[</span><span class="n">mod_name</span><span class="o">+</span><span class="s1">&#39;.&#39;</span><span class="o">+</span><span class="n">s_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">s</span>
            <span class="k">return</span> <span class="n">o</span>
        <span class="k">return</span> <span class="n">rec</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></div>
<div class="viewcode-block" id="Layer.set_state"><a class="viewcode-back" href="../../docs.html#convis.base.Layer.set_state">[docs]</a>    <span class="k">def</span> <span class="nf">set_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            collects the state and returns an</span>
<span class="sd">            OrderedDict </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">def</span> <span class="nf">rec</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">sub_state_dict</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="s1">&#39;_state&#39;</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">s_name</span><span class="p">,</span><span class="n">s</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">_state</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="nb">setattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">s_name</span><span class="p">,</span> <span class="n">sub_state_dict</span><span class="p">[</span><span class="n">s_name</span><span class="p">])</span>
            <span class="k">for</span> <span class="n">mod_name</span><span class="p">,</span><span class="n">mod</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">named_modules</span><span class="p">()):</span>
                <span class="k">if</span> <span class="n">mod</span> <span class="ow">is</span> <span class="n">model</span><span class="p">:</span>
                    <span class="k">continue</span>
                <span class="n">new_sub_state_dict</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
                <span class="k">for</span> <span class="n">s_name</span><span class="p">,</span><span class="n">s</span> <span class="ow">in</span> <span class="n">sub_state_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="k">if</span> <span class="n">s_name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">mod_name</span><span class="o">+</span><span class="s1">&#39;.&#39;</span><span class="p">):</span>
                        <span class="n">new_sub_state_dict</span><span class="p">[</span><span class="n">s_name</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">mod_name</span><span class="o">+</span><span class="s1">&#39;.&#39;</span><span class="p">):]]</span> <span class="o">=</span> <span class="n">s</span>
                <span class="n">rec</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">new_sub_state_dict</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">rec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">)</span></div>
<div class="viewcode-block" id="Layer.clear_state"><a class="viewcode-back" href="../../docs.html#convis.base.Layer.clear_state">[docs]</a>    <span class="k">def</span> <span class="nf">clear_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            resets the state to default values</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">def</span> <span class="nf">rec</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
            <span class="n">o</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="s1">&#39;_state&#39;</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">s_name</span><span class="p">,</span><span class="n">s</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">_state</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="s1">&#39;_default_state&#39;</span><span class="p">):</span>
                        <span class="n">old_val</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">_state</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">s_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                        <span class="nb">setattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">s_name</span><span class="p">,</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">_default_state</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">s_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)))</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">old_val</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">_state</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">s_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                        <span class="nb">setattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">s_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                    <span class="n">o</span><span class="p">[</span><span class="n">s_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">old_val</span><span class="p">,</span><span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">s_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">mod_name</span><span class="p">,</span><span class="n">mod</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">named_modules</span><span class="p">()):</span>
                <span class="k">if</span> <span class="n">mod</span> <span class="ow">is</span> <span class="n">model</span><span class="p">:</span>
                    <span class="k">continue</span>
                <span class="k">for</span> <span class="n">s_name</span><span class="p">,</span><span class="n">s</span> <span class="ow">in</span> <span class="n">rec</span><span class="p">(</span><span class="n">mod</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="n">o</span><span class="p">[</span><span class="n">mod_name</span><span class="o">+</span><span class="s1">&#39;.&#39;</span><span class="o">+</span><span class="n">s_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">s</span>
            <span class="k">return</span> <span class="n">o</span>
        <span class="k">return</span> <span class="n">rec</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></div>
<div class="viewcode-block" id="Layer.push_state"><a class="viewcode-back" href="../../docs.html#convis.base.Layer.push_state">[docs]</a>    <span class="k">def</span> <span class="nf">push_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            collects all State variables and pushes they values onto a stack</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_state_stack&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_state_stack</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_state_stack</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">())</span></div>
<div class="viewcode-block" id="Layer.pop_state"><a class="viewcode-back" href="../../docs.html#convis.base.Layer.pop_state">[docs]</a>    <span class="k">def</span> <span class="nf">pop_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            retrieves the values of all State variables and from a stack</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_state_stack&#39;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;No state was pushed to the stack!&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_state_stack</span><span class="o">.</span><span class="n">pop</span><span class="p">())</span></div>
    <span class="k">def</span> <span class="nf">_repr_html_</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">variable_describe</span><span class="o">.</span><span class="n">describe_layer_with_html</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<div class="viewcode-block" id="Layer.plot_impulse"><a class="viewcode-back" href="../../docs.html#convis.base.Layer.plot_impulse">[docs]</a>    <span class="k">def</span> <span class="nf">plot_impulse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">shp</span><span class="o">=</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">),</span><span class="n">dt</span><span class="o">=</span><span class="mi">500</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Plots the response to a 1 bin impulse.</span>

<span class="sd">            The state of the model is preserved (pushed </span>
<span class="sd">            to the stack and poped later).</span>


<span class="sd">            Attributes</span>
<span class="sd">            ----------</span>

<span class="sd">            shp : tuple(t, x, y)</span>
<span class="sd">                the size of the stimulus. A larger stimulus</span>
<span class="sd">                will show a larger area of the impulse response</span>
<span class="sd">            dt : int</span>
<span class="sd">                length of chunks when computing the response</span>

<span class="sd">            Returns</span>
<span class="sd">            -------</span>
<span class="sd">            The output of the model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">.</span> <span class="k">import</span> <span class="n">plot_5d_time</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">push_state</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clear_state</span><span class="p">()</span>
        <span class="n">inp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shp</span><span class="p">)</span>
        <span class="n">inp</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="nb">int</span><span class="p">(</span><span class="n">shp</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">/</span><span class="mi">2</span><span class="p">),</span><span class="nb">int</span><span class="p">(</span><span class="n">shp</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">/</span><span class="mi">2</span><span class="p">)]</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="n">o</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span><span class="n">dt</span><span class="o">=</span><span class="n">dt</span><span class="p">)</span>
        <span class="n">plot_5d_time</span><span class="p">(</span><span class="n">o</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pop_state</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">o</span></div>
<div class="viewcode-block" id="Layer.plot_impulse_space"><a class="viewcode-back" href="../../docs.html#convis.base.Layer.plot_impulse_space">[docs]</a>    <span class="k">def</span> <span class="nf">plot_impulse_space</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">shp</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">20</span><span class="p">),</span><span class="n">dt</span><span class="o">=</span><span class="mi">500</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Plots the response to a 1 bin impulse.</span>

<span class="sd">            The state of the model is preserved (pushed </span>
<span class="sd">            to the stack and poped later).</span>


<span class="sd">            Attributes</span>
<span class="sd">            ----------</span>

<span class="sd">            shp : tuple(t, x, y)</span>
<span class="sd">                the size of the stimulus. A larger stimulus</span>
<span class="sd">                will show a larger area of the impulse response</span>
<span class="sd">            dt : int</span>
<span class="sd">                length of chunks when computing the response</span>

<span class="sd">            Returns</span>
<span class="sd">            -------</span>
<span class="sd">            The output of the model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">.</span> <span class="k">import</span> <span class="n">plot_5d_matshow</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">push_state</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clear_state</span><span class="p">()</span>
        <span class="n">inp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shp</span><span class="p">)</span>
        <span class="n">inp</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="nb">int</span><span class="p">(</span><span class="n">shp</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">/</span><span class="mi">2</span><span class="p">),</span><span class="nb">int</span><span class="p">(</span><span class="n">shp</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">/</span><span class="mi">2</span><span class="p">)]</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="n">o</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span><span class="n">dt</span><span class="o">=</span><span class="n">dt</span><span class="p">)</span>
        <span class="n">plot_5d_matshow</span><span class="p">(</span><span class="n">o</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pop_state</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">o</span></div></div>

<span class="n">Model</span> <span class="o">=</span> <span class="n">Layer</span>

<span class="kn">from</span> <span class="nn">collections</span> <span class="k">import</span> <span class="n">OrderedDict</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="k">def</span> <span class="nf">get_next</span><span class="p">(</span><span class="n">stream</span><span class="p">,</span><span class="n">l</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">stream</span><span class="p">,</span> <span class="s1">&#39;get&#39;</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">stream</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">l</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">stream</span><span class="p">,</span> <span class="s1">&#39;__next__&#39;</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">next</span><span class="p">(</span><span class="n">stream</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">type</span><span class="p">(</span><span class="n">stream</span><span class="p">)</span> <span class="o">==</span> <span class="nb">list</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">stream</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">stream</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">StopIteration</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">stream</span>

<span class="k">class</span> <span class="nc">_DummyModel</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>
    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">chunk_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">inps</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">([(</span><span class="n">k</span><span class="p">,</span><span class="n">get_next</span><span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="n">l</span><span class="o">=</span><span class="n">chunk_size</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">())</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">()])</span>
        <span class="k">return</span> <span class="n">Output</span><span class="p">(</span><span class="n">inps</span><span class="o">.</span><span class="n">values</span><span class="p">(),</span><span class="n">keys</span><span class="o">=</span><span class="n">inps</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        
<div class="viewcode-block" id="Runner"><a class="viewcode-back" href="../../docs.html#convis.base.Runner">[docs]</a><span class="k">class</span> <span class="nc">Runner</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Keeps track of the input and output of a model</span>
<span class="sd">        and can run or optimize it in a separate thread.</span>

<span class="sd">        :attr:`model` has to be a :class:`convis.base.Layer`</span>

<span class="sd">        :attr:`input` should be a :class:`convis.streams.Stream` that contains input data</span>
<span class="sd">        :attr:`output` should be a :class:`convis.streams.Stream` that accepts new data</span>
<span class="sd">        when using optimize, :attr:`goal` has to have the same length as input and the same behaviour at the end of the stream (repeating or stop)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">goal</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input</span> <span class="o">=</span> <span class="nb">input</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">output</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">goal</span> <span class="o">=</span> <span class="n">goal</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">chunk_size</span> <span class="o">=</span> <span class="mi">20</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">closed</span> <span class="o">=</span> <span class="kc">True</span>
<div class="viewcode-block" id="Runner.stop"><a class="viewcode-back" href="../../docs.html#convis.base.Runner.stop">[docs]</a>    <span class="k">def</span> <span class="nf">stop</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">closed</span> <span class="o">=</span> <span class="kc">True</span></div>
<div class="viewcode-block" id="Runner.start"><a class="viewcode-back" href="../../docs.html#convis.base.Runner.start">[docs]</a>    <span class="k">def</span> <span class="nf">start</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">closed</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="kn">import</span> <span class="nn">thread</span>
            <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
                <span class="kn">import</span> <span class="nn">_thread</span> <span class="k">as</span> <span class="nn">thread</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">closed</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">start_time</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
            <span class="n">thread</span><span class="o">.</span><span class="n">start_new_thread</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">thread</span><span class="p">,</span><span class="nb">tuple</span><span class="p">())</span></div>
    <span class="k">def</span> <span class="nf">thread</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="kn">import</span> <span class="nn">time</span><span class="o">,</span> <span class="nn">datetime</span>
        <span class="k">while</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">closed</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
            <span class="k">except</span> <span class="ne">StopIteration</span><span class="p">:</span>
                <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
            <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
<div class="viewcode-block" id="Runner.run"><a class="viewcode-back" href="../../docs.html#convis.base.Runner.run">[docs]</a>    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">length</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">length</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">xrange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">length</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">chunk_size</span><span class="p">):</span>
                <span class="n">o</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input</span><span class="p">,</span> <span class="n">dt</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">chunk_size</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">o</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
            <span class="k">return</span> <span class="n">o</span> 
        <span class="k">else</span><span class="p">:</span>
            <span class="n">o</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">get_next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input</span><span class="p">))</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">o</span><span class="p">,</span><span class="s1">&#39;keys&#39;</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">o</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">o</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
            <span class="k">return</span> <span class="n">o</span></div>
<div class="viewcode-block" id="Runner.optimize"><a class="viewcode-back" href="../../docs.html#convis.base.Runner.optimize">[docs]</a>    <span class="k">def</span> <span class="nf">optimize</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">o</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">get_next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input</span><span class="p">),</span> <span class="n">get_next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">goal</span><span class="p">))</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">o</span><span class="p">,</span><span class="s1">&#39;keys&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">o</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">o</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">o</span></div></div>
</pre></div>

      </div>
      <div class="bottomnav" role="navigation" aria-label="bottom navigation">
      
        <p>
        <a class="uplink" href="../../index.html">Contents</a>
        </p>

      </div>

    <div class="footer" role="contentinfo">
        &#169; Copyright 2016, Jacob Huth.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.6.6.
    </div>
  </body>
</html>